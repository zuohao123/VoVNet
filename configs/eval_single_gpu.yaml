model:
  torch_dtype: "float16"

eval:
  batch_size: 1
