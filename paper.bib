%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Benchmarks / Datasets
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@inproceedings{liu2024mmbench,
  title     = {MMBench: Is Your Multi-modal Model an All-around Player?},
  author    = {Liu, Yuan and Duan, Haodong and Zhang, Yuanhan and Li, Bo and Zhang, Songyang and Zhao, Wangbo and Yuan, Yike and Wang, Jiaqi and He, Conghui and Liu, Ziwei and Chen, Kai and Lin, Dahua},
  booktitle = {Proceedings of the European Conference on Computer Vision (ECCV)},
  year      = {2024},
  doi       = {10.1007/978-3-031-72658-3_13}
}

@article{singh2019textvqa,
  title   = {Towards VQA Models That Can Read},
  author  = {Singh, Amanpreet and Natarjan, Vivek and Shah, Meet and Jiang, Yu and Chen, Xinlei and Batra, Dhruv and Parikh, Devi and Rohrbach, Marcus},
  journal = {arXiv preprint arXiv:1904.08920},
  year    = {2019},
  doi     = {10.48550/arXiv.1904.08920}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Vision-Language Models / Instruction Tuning
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@inproceedings{alayrac2022flamingo,
  title     = {Flamingo: a Visual Language Model for Few-Shot Learning},
  author    = {Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katie and Reynolds, Malcolm and Ring, Roman and Rutherford, Eliza and Cabi, Serkan and Brock, Andrew and Doersch, Carl and Fan, Angela and Fergus, Rob and Gray, Alexander and Hadsell, Raia and Huang, Po-Sen and Kavukcuoglu, Koray and Li, Michael and Vinyals, Oriol and Wierstra, Daan and Zisserman, Andrew and Simonyan, Karen},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2022}
}

@inproceedings{li2023blip2,
  title     = {BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models},
  author    = {Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven C. H.},
  booktitle = {Proceedings of the International Conference on Machine Learning (ICML)},
  year      = {2023}
}

@article{chen2022pali,
  title   = {PaLI: A Jointly-Scaled Multilingual Language-Image Model},
  author  = {Chen, Xi and Wang, Xiao and Changpinyo, Soravit and Lee, Kyunghyun and Wang, Lijun and Yu, Yukun and Tuzel, Oncel and Wu, Jiawei and Goodman, Noah and Li, Yonghui and Chen, Wenliang},
  journal = {arXiv preprint arXiv:2209.06794},
  year    = {2022},
  doi     = {10.48550/arXiv.2209.06794}
}

@article{bai2023qwenvl,
  title   = {Qwen-VL: A Versatile Vision-Language Model},
  author  = {Bai, Jinze and Bai, Shuai and Chu, Yun and Cui, Ziniu and Dang, Kai and Deng, Xiaoyi and Fan, Yang and Fang, Shihan and Gao, Bowen and Guo, Hongjin and Huang, Haotian and Huang, Jiaqi and Li, Bing and Li, Yuhui and Li, Yuze and Liu, Chujie and Liu, Jing and Liu, Kai and Liu, Yang and Liu, Yujie and Ma, Junxing and Ning, Qinyuan and Qiu, Qipeng and Ren, Renjie and Tan, Shifeng and Wang, Jingdong and Wang, Wenyu and Wen, Zhisheng and Wu, Yixin and Xu, Bin and Xu, Dongkuan and Xu, Jun and Yang, Cheng and Yang, Shijun and Zhou, Ziyi and Zhu, Junnan},
  journal = {arXiv preprint arXiv:2308.12966},
  year    = {2023},
  doi     = {10.48550/arXiv.2308.12966}
}

@article{liu2023llava,
  title   = {Visual Instruction Tuning},
  author  = {Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  journal = {arXiv preprint arXiv:2304.08485},
  year    = {2023},
  doi     = {10.48550/arXiv.2304.08485}
}

@article{dai2023instructblip,
  title   = {InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning},
  author  = {Dai, Wenliang and others},
  journal = {arXiv preprint arXiv:2305.06500},
  year    = {2023},
  doi     = {10.48550/arXiv.2305.06500}
}

@article{zhu2023minigpt4,
  title   = {MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models},
  author  = {Zhu, Deyao and others},
  journal = {arXiv preprint arXiv:2304.10592},
  year    = {2023},
  doi     = {10.48550/arXiv.2304.10592}
}

@article{laurencon2023idefics,
  title   = {IDEFICS: An Open Access Foundation Model for Multimodal Generation},
  author  = {Laurencon, Hugo and others},
  journal = {arXiv preprint arXiv:2306.16527},
  year    = {2023},
  doi     = {10.48550/arXiv.2306.16527}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% OCR / Open-domain Visual Recognition
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@article{hu2023open,
  title   = {Open-domain Visual Entity Recognition: Towards Recognizing Millions of Wikipedia Entities},
  author  = {Hu, Hexiang and Luan, Yi and Chen, Yang and Khandelwal, Urvashi and Joshi, Mandar and Lee, Kenton and Toutanova, Kristina and Chang, Ming-Wei},
  journal = {arXiv preprint arXiv:2302.11154},
  year    = {2023},
  doi     = {10.48550/arXiv.2302.11154}
}

@inproceedings{guan2023ccd,
  title     = {Self-Supervised Character-to-Character Distillation for Text Recognition},
  author    = {Guan, Tongkun and Shen, Wei and Yang, Xue and Feng, Qi and Jiang, Zekun and Yang, Xiaokang},
  booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  month     = {October},
  year      = {2023},
  pages     = {19473--19484}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Agentic / Interleaved Multimodal Reasoning
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@article{chung2025dontlook,
  title   = {Don't Look Only Once: Towards Multimodal Interactive Reasoning with Selective Visual Revisitation},
  author  = {Chung, Jiwan and Kim, Junhyeok and Kim, Siyeol and Lee, Jaeyoung and Kim, Min Soo and Yu, Youngjae},
  journal = {arXiv preprint arXiv:2505.18842},
  year    = {2025},
  doi     = {10.48550/arXiv.2505.18842}
}

@article{zhi2025srice,
  title   = {Seeing and Reasoning with Confidence: Supercharging Multimodal LLMs with an Uncertainty-Aware Agentic Framework},
  author  = {Zhi, Zhuo and Feng, Chen and Daneshmend, Adam and Orlu, Mine and Demosthenous, Andreas and Yin, Lu and Li, Da and Liu, Ziquan and Rodrigues, Miguel R. D.},
  journal = {arXiv preprint arXiv:2503.08308},
  year    = {2025},
  doi     = {10.48550/arXiv.2503.08308}
}

@article{dong2025ilvr,
  title   = {Interleaved Latent Visual Reasoning with Selective Perceptual Modeling},
  author  = {Dong, Shuai and Wang, Siyuan and Liu, Xingyu and Wei, Zhongyu},
  journal = {arXiv preprint arXiv:2512.05665},
  year    = {2025},
  doi     = {10.48550/arXiv.2512.05665}
}

@article{wang2025vicot,
  title   = {VICoT-Agent: A Vision-Interleaved Chain-of-Thought Framework for Interpretable Multimodal Reasoning and Scalable Remote Sensing Analysis},
  author  = {Wang, Chujie and Luo, Zhiyuan and Liu, Ruiqi and Ran, Can and Fan, Shenghua and Chen, Xi and He, Chu},
  journal = {arXiv preprint arXiv:2511.20085},
  year    = {2025},
  doi     = {10.48550/arXiv.2511.20085}
}

@inproceedings{huang2025icov,
  title     = {Autonomous Multimodal Reasoning via Implicit Chain-of-Vision},
  author    = {Huang, Yiqiao and He, Qi and Chen, Zhaorun and Zhang, Haopeng and Yu, Hanchao and Zhao, Zhuokai},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
  month     = {June},
  year      = {2025},
  pages     = {2988--2997}
}

@article{hu2024visualsketchpad,
  title   = {Visual Sketchpad: Sketching as a Visual Chain of Thought for Multimodal Language Models},
  author  = {Hu, Yushi and Shi, Weijia and Fu, Xingyu and Roth, Dan and Ostendorf, Mari and Zettlemoyer, Luke and Smith, Noah A. and Krishna, Ranjay},
  journal = {arXiv preprint arXiv:2406.09403},
  year    = {2024},
  doi     = {10.48550/arXiv.2406.09403}
}

@article{su2025thinking,
  title   = {Thinking with Images for Multimodal Reasoning: Foundations, Methods, and Future Frontiers},
  author  = {Su, Zhaochen and Xia, Peng and Guo, Hangyu and Liu, Zhenhua and Ma, Yan and Qu, Xiaoye and Liu, Jiaqi and Li, Yanshu and Zeng, Kaide and Yang, Zhengyuan and Li, Linjie and Cheng, Yu and Ji, Heng and He, Junxian and Fung, Yi R.},
  journal = {arXiv preprint arXiv:2506.23918},
  year    = {2025},
  doi     = {10.48550/arXiv.2506.23918}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Efficient Vision Encoding / Resolution Scaling
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@inproceedings{vasu2025fastvlm,
  title     = {FastVLM: Efficient Vision Encoding for Vision-Language Models},
  author    = {Vasu, Pavan Kumar Anasosalu and Faghri, Fartash and Li, Chun-Liang and Koc, Cem and True, Nate and Antony, Albert and Santhanam, Gokul and Gabriel, James and Grasch, Peter and Tuzel, Oncel and Pouransari, Hadi},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2025}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Visual Token Pruning / Merging / Manipulation
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@inproceedings{ryoo2021tokenlearner,
  title     = {TokenLearner: What Can 8 Learned Tokens Do for Images and Videos?},
  author    = {Ryoo, Michael S. and others},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2021}
}

@inproceedings{rao2021dynamicvit,
  title     = {DynamicViT: Efficient Vision Transformers with Dynamic Token Sparsification},
  author    = {Rao, Yongming and others},
  booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  year      = {2021}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Modality Selection / Value of Information
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@article{arevalo2017gmu,
  title   = {Gated Multimodal Units for Information Fusion},
  author  = {Arevalo, John and Solorio, Thamar and Montes-y-Gomez, Manuel and Gonzalez, Fabio A.},
  journal = {arXiv preprint arXiv:1702.01992},
  year    = {2017},
  doi     = {10.48550/arXiv.1702.01992}
}

@article{howard1966information,
  title   = {Information Value Theory},
  author  = {Howard, Ronald A.},
  journal = {IEEE Transactions on Systems Science and Cybernetics},
  year    = {1966},
  volume  = {2},
  number  = {1},
  pages   = {22--26},
  doi     = {10.1109/TSSC.1966.300074}
}

@inproceedings{janisch2019costly,
  title     = {Classification with Costly Features Using Deep Reinforcement Learning},
  author    = {Janisch, Jiri and Pevny, Tomas and Lisy, Viliam},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  year      = {2019},
  volume    = {33},
  pages     = {3959--3966},
  doi       = {10.1609/aaai.v33i01.33013959}
}

@inproceedings{bolya2023tome,
  title     = {Token Merging: Your ViT but Faster},
  author    = {Bolya, Daniel and others},
  booktitle = {Proceedings of the International Conference on Learning Representations (ICLR)},
  year      = {2023}
}

@inproceedings{ye2025atpllava,
  title     = {ATP-LLaVA: Adaptive Token Pruning for Large Vision Language Models},
  author    = {Ye, Xubing and Gan, Yukang and Ge, Yixiao and Zhang, Xiao-Ping and Tang, Yansong},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2025}
}

@inproceedings{ye2025fitprune,
  title     = {Fit and Prune: Fast and Training-free Visual Token Pruning for Multi-modal Large Language Models},
  author    = {Ye, Weihao and Wu, Qiong and Lin, Wenhao and Zhou, Yiyi},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)},
  year      = {2025},
  doi       = {10.1609/aaai.v39i21.34366}
}

@inproceedings{zhong2025aim,
  title     = {AIM: Adaptive Inference of Multi-Modal LLMs via Token Merging and Pruning},
  author    = {Zhong, Yiwu and Liu, Zhuoming and Li, Yin and Wang, Liwei},
  booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  year      = {2025}
}

@inproceedings{zhang2025vispruner,
  title     = {Beyond Text-Visual Attention: Exploiting Visual Cues for Effective Token Pruning in VLMs},
  author    = {Zhang, Qizhe and Cheng, Aosong and Lu, Ming and Zhang, Renrui and Zhuo, Zhiyong and Cao, Jiajun and Guo, Shaobo and She, Qi and Zhang, Shanghang},
  booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  year      = {2025}
}

@inproceedings{yuan2025dtoma,
  title     = {DToMA: Training-free Dynamic Token Manipulation for Long Video Understanding},
  author    = {Yuan, Bowen and You, Sisi and Bao, Bing-Kun},
  booktitle = {Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI)},
  year      = {2025},
  doi       = {10.24963/ijcai.2025/258}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Multi-granularity / Nested Representations
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@article{chen2024m3,
  title   = {Matryoshka Multimodal Models},
  author  = {Chen, Zhe and Li, Mingda and Zhang, Yuhui and Chen, Wenhu},
  journal = {arXiv preprint arXiv:2406.04330},
  year    = {2024},
  doi     = {10.48550/arXiv.2406.04330}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Adaptive Computation / Early Exit
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@article{graves2016act,
  title   = {Adaptive Computation Time for Recurrent Neural Networks},
  author  = {Graves, Alex},
  journal = {arXiv preprint arXiv:1603.08983},
  year    = {2016},
  doi     = {10.48550/arXiv.1603.08983}
}

@inproceedings{wang2018skipnet,
  title     = {SkipNet: Learning Dynamic Routing in Convolutional Networks},
  author    = {Wang, Lan and others},
  booktitle = {Proceedings of the European Conference on Computer Vision (ECCV)},
  year      = {2018}
}

@inproceedings{xin2020deebert,
  title     = {DeeBERT: Dynamic Early Exiting for Accelerating BERT Inference},
  author    = {Xin, Ji and Tang, Raphael and Lee, Jaejun and Yu, Yaoliang and Lin, Jimmy},
  booktitle = {Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)},
  year      = {2020},
  doi       = {10.18653/v1/2020.acl-main.204}
}

@article{teerapittayanon2017branchynet,
  title   = {BranchyNet: Fast Inference via Early Exiting from Deep Neural Networks},
  author  = {Teerapittayanon, Surat and McDanel, Bradley and Kung, H. T.},
  journal = {arXiv preprint arXiv:1709.01686},
  year    = {2017},
  doi     = {10.48550/arXiv.1709.01686}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% System-level Efficient VLM Inference
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@inproceedings{shao2025twigvlm,
  title     = {Growing a Twig to Accelerate Large Vision-Language Models},
  author    = {Shao, Zhenwei and Wang, Mingyang and Yu, Zhou and Pan, Wenwen and Yang, Yan and Wei, Tao and Zhang, Hongyuan and Mao, Ning and Chen, Wei and Yu, Jun},
  booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  year      = {2025}
}

@inproceedings{chen2024videollm,
  title     = {VideoLLM-online: Online Video Large Language Model for Streaming Video},
  author    = {Chen, Joya and Lv, Zhaoyang and Wu, Shiwei and Lin, Kevin Qinghong and Song, Chenan and Gao, Difei and Liu, Jia-Wei and Gao, Ziteng and Mao, Dongxing and Shou, Mike Zheng},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2024}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Uncertainty / Selective Prediction
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@article{geifman2017selective,
  title   = {Selective Classification for Deep Neural Networks},
  author  = {Geifman, Yonatan and El-Yaniv, Ran},
  journal = {arXiv preprint arXiv:1705.08500},
  year    = {2017},
  doi     = {10.48550/arXiv.1705.08500}
}

@inproceedings{geifman2019selectivenet,
  title     = {SelectiveNet: A Deep Neural Network with an Integrated Reject Option},
  author    = {Geifman, Yonatan and El-Yaniv, Ran},
  booktitle = {Proceedings of the International Conference on Machine Learning (ICML)},
  year      = {2019}
}

@inproceedings{nath2025harmony,
  title     = {HARMONY: Harnessing LLM and Sparse Human Visual Labels for Explainable and Trustworthy Visual Question Answering},
  author    = {Nath, Dibyen and Pal, Vaishnavi and Bhattacharya, Debarpan and Walambe, Rahee and Bairagi, Vinayak and Kotecha, Ketan},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
  year      = {2025},
  pages     = {5963--5974},
  doi       = {10.1109/CVPRW73612.2025.00628}
}

@inproceedings{bhattacharya2025festa,
  title     = {FESTA: Chain-of-Thought Prompting for Vision-Language Models in Long-Form Sequential Decision-Making},
  author    = {Bhattacharya, Debarpan and Kulkarni, Apoorva and Ganapathy, Sriram},
  booktitle = {Findings of the Association for Computational Linguistics: EMNLP 2025},
  year      = {2025},
  pages     = {12277--12295},
  url       = {https://aclanthology.org/2025.findings-emnlp.657}
}

@article{srinivasan2024recoverr,
  title   = {Selective ``Selective Prediction'': Reducing Unnecessary Abstention in Vision-Language Reasoning},
  author  = {Srinivasan, Tejas and Hessel, Jack and Gupta, Tanmay and Lin, Bill Yuchen and Choi, Yejin and Thomason, Jesse and Chandu, Khyathi Raghavi},
  journal = {arXiv preprint arXiv:2402.15610},
  year    = {2024},
  doi     = {10.48550/arXiv.2402.15610}
}

@article{angelopoulos2021conformal,
  title   = {A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification},
  author  = {Angelopoulos, Anastasios N. and Bates, Stephen},
  journal = {arXiv preprint arXiv:2107.07511},
  year    = {2021},
  doi     = {10.48550/arXiv.2107.07511}
}

@article{romano2020classification,
  title   = {Classification with Valid and Adaptive Coverage},
  author  = {Romano, Yaniv and Sesia, Matteo and Cand{\`e}s, Emmanuel J.},
  journal = {arXiv preprint arXiv:2006.02544},
  year    = {2020},
  doi     = {10.48550/arXiv.2006.02544}
}
